{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import holidays\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\Emincan\\Desktop\\Gdz\\gdz-competition\\Önemli Scriptler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv' , parse_dates=['Tarih'] )\n",
    "submit = pd.read_csv('sample_submission.csv', parse_dates=['Tarih'])\n",
    "med = pd.read_csv('med.csv' , parse_dates=['Tarih'])\n",
    "\n",
    "\n",
    "calendar = pd.read_csv('Turkish_calendar.csv',sep=(\";\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feat_engs import create_time_features1 , create_time_features2\n",
    "\n",
    "# data , submit = create_time_features1(data , med , calendar ,submit_df)\n",
    "data = create_time_features2(data , med)\n",
    "submit = create_time_features2(submit , med)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16,20) , dpi=100)\n",
    "sns.heatmap(data.corr(numeric_only=True).round(2) , annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16,12) , dpi=100)\n",
    "sns.heatmap(submit.corr(numeric_only=True).round(2) , annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.drop(['electrical_outage' , 'outage_percentage' , 'rolling_outages_24h' , 'exp_avg_outages_24h' , 'is_weekend' , 'is_winter' , 'is_weekday'] , axis = 1 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train | Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index('Tarih' , inplace=True)\n",
    "submit.set_index('Tarih' , inplace=True)\n",
    "\n",
    "data['week_of_year'] = data['week_of_year'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop(\"Dağıtılan Enerji (MWh)\", axis=1)\n",
    "y=data[\"Dağıtılan Enerji (MWh)\"]\n",
    "# forecast=submit.drop(\"Dağıtılan Enerji (MWh)\", axis=1)\n",
    "forecast = submit.copy().drop('Dağıtılan Enerji (MWh)' , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2 , random_state=53 , shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_forecast_scaled = scaler.transform(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def packager(X_scaled, X_train_scaled, X_test_scaled, X_forecast_scaled, window_size=24):\n",
    "    X_3d, y_2d, X_train_3d, y_train_2d, X_test_3d, y_test_2d, X_forecast_3d = [], [], [], [], [], [], []\n",
    "    \n",
    "    for i in range(window_size, len(X_scaled)):\n",
    "        X_3d.append(X_scaled[i-window_size:i, :])\n",
    "        y_2d.append(X_scaled[i, 0])\n",
    "\n",
    "    for i in range(window_size, len(X_train_scaled)):\n",
    "        X_train_3d.append(X_train_scaled[i-window_size:i, :])\n",
    "        y_train_2d.append(X_train_scaled[i, 0])\n",
    "\n",
    "    for i in range(window_size, len(X_test_scaled)):\n",
    "        X_test_3d.append(X_test_scaled[i-window_size:i, :])\n",
    "        y_test_2d.append(X_test_scaled[i, 0])\n",
    "        \n",
    "    for i in range(window_size, len(X_forecast_scaled)):\n",
    "        X_forecast_3d.append(X_forecast_scaled[i-window_size:i, :])\n",
    "\n",
    "    X_3d, y_2d = np.array(X_3d), np.array(y_2d)\n",
    "    X_train_3d, y_train_2d = np.array(X_train_3d), np.array(y_train_2d)\n",
    "    X_test_3d, y_test_2d = np.array(X_test_3d), np.array(y_test_2d)\n",
    "    X_forecast_3d = np.array(X_forecast_3d)\n",
    "\n",
    "    X_3d = np.reshape(X_3d, (X_3d.shape[0], X_3d.shape[1], X_3d.shape[2]))\n",
    "    X_train_3d = np.reshape(X_train_3d, (X_train_3d.shape[0], X_train_3d.shape[1], X_train_3d.shape[2]))\n",
    "    X_test_3d = np.reshape(X_test_3d, (X_test_3d.shape[0], X_test_3d.shape[1], X_test_3d.shape[2]))\n",
    "    X_forecast_3d = np.reshape(X_forecast_3d, (X_forecast_3d.shape[0], X_forecast_3d.shape[1], X_forecast_3d.shape[2]))\n",
    "\n",
    "    return X_3d, y_2d, X_train_3d, y_train_2d, X_test_3d, y_test_2d, X_forecast_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3d, y_2d, X_train_3d, y_train_2d, X_test_3d, y_test_2d, X_forecast_3d = packager(X_scaled, X_train_scaled, X_test_scaled, X_forecast_scaled,  24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X_3d Shape : {X_3d.shape}\")\n",
    "print(f\"y_2d Shape : {y_2d.shape}\\n\\n\")\n",
    "print(f\"X_train_3d Shape : {X_train_3d.shape}\")\n",
    "print(f\"y_train_2d Shape : {y_train_2d.shape}\\n\\n\")\n",
    "print(f\"X_test_3d Shape : {X_test_3d.shape}\")\n",
    "print(f\"y_test_2d Shape : {y_test_2d.shape}\\n\\n\")\n",
    "print(f\"X_forecast_3d Shape : {X_forecast_3d.shape}\")\n",
    "# print(f\"y_future Shape : {y_future.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Target label + Multi features and NO---ovlap\n",
    "\n",
    "# time_steps = 24\n",
    "\n",
    "# def packager(X_scaled, X_forecast_scaled ,X_train_scaled, X_test_scaled, time_steps=24):\n",
    "#     X_3d, y_2d, X_forecast_3d , y_forecast ,X_train_3d, y_train_2d, X_test_3d, y_test_2d = [], [], [], [], [], [] , [], []\n",
    "\n",
    "#     for i in range(0, len(X_scaled)-time_steps, time_steps):\n",
    "#         X_3d.append(X_scaled[i:i+time_steps, :])\n",
    "#         X_3d.append(X_scaled[i+time_steps, 0])\n",
    "        \n",
    "#     for i in range(0, len(X_forecast_scaled)-time_steps, time_steps):\n",
    "#         X_forecast_3d.append(X_forecast_scaled[i:i+time_steps, :])\n",
    "#         y_forecast.append(X_forecast_scaled[i+time_steps, 0])\n",
    "\n",
    "#     for i in range(0, len(X_train_scaled)-time_steps, time_steps):\n",
    "#         X_train_3d.append(X_train_scaled[i:i+time_steps, :])\n",
    "#         y_train_2d.append(X_train_scaled[i+time_steps, 0])\n",
    "\n",
    "#     for i in range(0, len(X_test_scaled)-time_steps, time_steps):\n",
    "#         X_test_3d.append(X_test_scaled[i:i+time_steps, :])\n",
    "#         y_test_2d.append(X_test_scaled[i+time_steps, 0])\n",
    "\n",
    "#     X_3d, y_2d = np.array(X_3d), np.array(y_2d)\n",
    "#     X_forecast_3d, y_forecast = np.array(X_forecast_3d), np.array(y_forecast)\n",
    "#     X_train_3d, y_train_2d = np.array(X_train_3d), np.array(y_train_2d)\n",
    "#     X_test_3d, y_test_2d = np.array(X_test_3d), np.array(y_test_2d)\n",
    "\n",
    "#     return X_3d, y_2d, X_forecast_3d, y_forecast, X_train_3d, y_train_2d, X_test_3d, y_test_2d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Seed ayarlamak\n",
    "seed_value = 53\n",
    "tf.keras.utils.set_random_seed(seed_value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "      Model eğitiminde kullandığımız dataların shapeleri\n",
    "      X_3d Shape : {X_3d.shape}\n",
    "      y_2d Shape : {y_2d.shape}\n",
    "      X_test_3d Shape : {X_test_3d.shape}\n",
    "      y_test_2d Shape : {y_test_2d.shape}\n",
    "      \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense , BatchNormalization , Dropout , GlobalAveragePooling1D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau , EarlyStopping\n",
    "from keras.optimizers import Adam , Adagrad , Adadelta , Nadam , RMSprop\n",
    "from keras.losses import MeanAbsolutePercentageError\n",
    "\n",
    "\n",
    "# Model oluşturma\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, activation='tanh' , input_shape = (X_3d.shape[1] , X_3d.shape[2]) ,return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(LSTM(128, activation='tanh' ,return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(64, activation='tanh' ,return_sequences=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(GlobalAveragePooling1D())\n",
    "# model.add(LSTM(12, activation='tanh' ,return_sequences=False))\n",
    "# model.add(LSTM(4, activation='tanh'  , return_sequences=False))\n",
    "model.add(Dense(24))\n",
    "\n",
    "opt = Adam(learning_rate = 0.01)\n",
    "model.compile(loss= MeanAbsolutePercentageError(), optimizer=opt)\n",
    "\n",
    "\n",
    "# reduce_lr = ReduceLROnPlateau(factor = 0.1 , patience=8)\n",
    "# early_stop = EarlyStopping(monitor='val_loss' , patience=7)\n",
    "model_check = ModelCheckpoint(filepath=r'C:\\Users\\Emincan\\Desktop\\Gdz\\gdz-competition\\Checkpoints\\justFeatures_wOverlap\\\\24-preds\\\\64d0.2-32d0.2-24dense(lr001-batch32)\\\\model-{epoch:03d}-{val_loss:.5f}.h5', monitor=\"val_loss\", verbose=1)\n",
    "\n",
    "# # Modeli eğitme\n",
    "history = model.fit(X_3d, y_2d, epochs=20, batch_size= 32, validation_split=0.1, callbacks= [model_check] , shuffle=False)\n",
    "\n",
    "\n",
    "# Modeli değerlendirme\n",
    "mape_score = model.evaluate(X_test_3d, y_test_2d)\n",
    "print('Test MAPE: %.3f' % mape_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Model History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(r\"C:\\Users\\Emincan\\Desktop\\Gdz\\gdz-competition\\Checkpoints\\justFeatures_NOovlap\\256-128-64-32d-24d(lr0001-batch32)\\\\model-038-12.65707.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_metrics import eval_metrics\n",
    "\n",
    "y_pred = model.predict(X_test_3d)\n",
    "\n",
    "eval_metrics(y_test_2d , y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_2d.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
