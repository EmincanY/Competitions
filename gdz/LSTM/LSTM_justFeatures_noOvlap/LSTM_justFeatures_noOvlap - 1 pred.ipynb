{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import holidays\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\Emincan\\Desktop\\Gdz\\gdz-competition\\Önemli Scriptler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv' , parse_dates=['Tarih'] )\n",
    "submit = pd.read_csv('sample_submission.csv', parse_dates=['Tarih'])\n",
    "med = pd.read_csv('med.csv' , parse_dates=['Tarih'])\n",
    "\n",
    "\n",
    "calendar = pd.read_csv('Turkish_calendar.csv',sep=(\";\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feat_engs import create_time_features1 , create_time_features2\n",
    "\n",
    "# data , submit = create_time_features1(data , med , calendar ,submit_df)\n",
    "data = create_time_features2(data , med)\n",
    "submit = create_time_features2(submit , med)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16,20) , dpi=100)\n",
    "sns.heatmap(data.corr(numeric_only=True).round(2) , annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16,12) , dpi=100)\n",
    "sns.heatmap(submit.corr(numeric_only=True).round(2) , annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.drop(['electrical_outage' , 'outage_percentage' , 'rolling_outages_24h' , 'exp_avg_outages_24h' , 'is_weekend' , 'is_winter' , 'is_weekday'] , axis = 1 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train | Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index('Tarih' , inplace=True)\n",
    "submit.set_index('Tarih' , inplace=True)\n",
    "\n",
    "data['week_of_year'] = data['week_of_year'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop(\"Dağıtılan Enerji (MWh)\", axis=1)\n",
    "y=data[\"Dağıtılan Enerji (MWh)\"]\n",
    "# forecast=submit.drop(\"Dağıtılan Enerji (MWh)\", axis=1)\n",
    "forecast = submit.copy().drop('Dağıtılan Enerji (MWh)' , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2 ,shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_forecast_scaled = scaler.transform(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlapsiz\n",
    "# 24 Time_stepse bakıp gelecekte sadece 1 time_step tahmin etme.\n",
    "\n",
    "time_steps = 24\n",
    "\n",
    "X_3d = []\n",
    "for i in range(0, len(X_scaled) - time_steps, time_steps):\n",
    "    X_3d.append(X_scaled[i:i+time_steps])\n",
    "\n",
    "X_3d = np.array(X_3d)\n",
    "\n",
    "\n",
    "y_2d = []\n",
    "for i in range(time_steps, len(y), time_steps):\n",
    "    y_2d.append(y[i])\n",
    "    \n",
    "y_2d = np.array(y_2d)\n",
    "\n",
    "\n",
    "X_train_3d = []\n",
    "for i in range(0, len(X_train_scaled) - time_steps, time_steps):\n",
    "    X_train_3d.append(X_train_scaled[i:i+time_steps])\n",
    "\n",
    "X_train_3d = np.array(X_train_3d)\n",
    "\n",
    "\n",
    "y_train_2d = []\n",
    "for i in range(time_steps, len(y_train), time_steps):\n",
    "    y_train_2d.append(y_train[i])\n",
    "    \n",
    "y_train_2d = np.array(y_train_2d)\n",
    "\n",
    "\n",
    "X_test_3d = []\n",
    "for i in range(0, len(X_test_scaled) - time_steps, time_steps):\n",
    "    X_test_3d.append(X_test_scaled[i:i+time_steps])\n",
    "\n",
    "X_test_3d = np.array(X_test_3d)\n",
    "\n",
    "\n",
    "y_test_2d = []\n",
    "for i in range(time_steps, len(y_test), time_steps):\n",
    "    y_test_2d.append(y_test[i])\n",
    "    \n",
    "y_test_2d = np.array(y_test_2d)\n",
    "\n",
    "\n",
    "X_forecast_3d = []\n",
    "for i in range(0, len(X_forecast_scaled) - time_steps, time_steps):\n",
    "    X_forecast_3d.append(X_forecast_scaled[i:i+time_steps])\n",
    "    \n",
    "X_forecast_3d = np.array(X_forecast_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X_3d Shape : {X_3d.shape}\")\n",
    "print(f\"y_2d Shape : {y_2d.shape}\\n\\n\")\n",
    "print(f\"X_train_3d Shape : {X_train_3d.shape}\")\n",
    "print(f\"y_train_2d Shape : {y_train_2d.shape}\\n\\n\")\n",
    "print(f\"X_test_3d Shape : {X_test_3d.shape}\")\n",
    "print(f\"y_test_2d Shape : {y_test_2d.shape}\\n\\n\")\n",
    "print(f\"X_forecast_3d Shape : {X_forecast_3d.shape}\")\n",
    "# print(f\"y_future Shape : {y_future.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Seed ayarlamak\n",
    "seed_value = 61\n",
    "tf.keras.utils.set_random_seed(seed_value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "      Model eğitiminde kullandığımız dataların shapeleri\n",
    "      X_3d Shape : {X_3d.shape}\n",
    "      y_2d Shape : {y_2d.shape}\n",
    "      X_test_3d Shape : {X_test_3d.shape}\n",
    "      y_test_2d Shape : {y_test_2d.shape}\n",
    "      \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense , BatchNormalization , Dropout , GlobalAveragePooling1D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau , EarlyStopping\n",
    "from keras.optimizers import Adam , Adagrad , Adadelta , Nadam , RMSprop\n",
    "from keras.losses import MeanAbsolutePercentageError\n",
    "\n",
    "\n",
    "# Model oluşturma\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, activation='tanh' , input_shape = (X_3d.shape[1] , X_3d.shape[2]) ,return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(24, activation='tanh' ,return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "# model.add(LSTM(32, activation='tanh' ,return_sequences=False))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(GlobalAveragePooling1D())\n",
    "# model.add(LSTM(12, activation='tanh' ,return_sequences=False))\n",
    "# model.add(LSTM(4, activation='tanh'  , return_sequences=False))\n",
    "model.add(Dense(1))\n",
    "\n",
    "opt = Adam(learning_rate = 0.01)\n",
    "model.compile(loss= MeanAbsolutePercentageError(), optimizer=opt)\n",
    "\n",
    "\n",
    "# reduce_lr = ReduceLROnPlateau(factor = 0.1 , patience=8)\n",
    "# early_stop = EarlyStopping(monitor='val_loss' , patience=7)\n",
    "model_check = ModelCheckpoint(filepath=r'C:\\Users\\Emincan\\Desktop\\Gdz\\gdz-competition\\Checkpoints\\justFeatures_NOovlap\\\\1-preds\\\\32d0.2-24d0.2(lr001-batch32)\\\\model-{epoch:03d}-{val_loss:.5f}.h5', monitor=\"val_loss\", verbose=1)\n",
    "\n",
    "# # Modeli eğitme\n",
    "history = model.fit(X_3d, y_2d, epochs=200, batch_size= 16, validation_split=0.1, callbacks= [model_check] , shuffle=False)\n",
    "\n",
    "\n",
    "# Modeli değerlendirme\n",
    "mape_score = model.evaluate(X_test_3d, y_test_2d)\n",
    "print('Test MAPE: %.3f' % mape_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Model History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(r\"C:\\Users\\Emincan\\Desktop\\Gdz\\gdz-competition\\Checkpoints\\justFeatures_NOovlap\\\\1-preds\\\\128d0.2-64d0.2-32d0.2-1dense(lr001-batch32)\\\\model-692-9.82838.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_metrics import eval_metrics\n",
    "\n",
    "y_pred = model.predict(X_test_3d)\n",
    "\n",
    "eval_metrics(y_test_2d , y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "      Model eğitiminde kullandığımız dataların shapeleri\n",
    "      X_3d Shape : {X_3d.shape}\n",
    "      y_2d Shape : {y_2d.shape}\n",
    "      X_test_3d Shape : {X_test_3d.shape}\n",
    "      y_test_2d Shape : {y_test_2d.shape}\n",
    "      \"\"\")\n",
    "\n",
    "print(f\"Modelin tahminlerinin alacağı future_data shape'i : {X_forecast_3d.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Son 744 saatlik verileri tahmin etme\n",
    "last_window = X_3d[-1:,:,:]\n",
    "\n",
    "# # Last window'ı ölçeklendirin\n",
    "# last_window_scaled = scaler.transform(last_window.reshape(-1, last_window.shape[-1])).reshape(last_window.shape)\n",
    "\n",
    "# Tahminler için bir dizi oluşturalım\n",
    "forecasts = []\n",
    "\n",
    "# Son 24 saatlik verilerle başlayalım\n",
    "current_window = last_window.reshape((1, last_window.shape[1], last_window.shape[2]))\n",
    "\n",
    "for i in range(744):\n",
    "    # Bu sıradaki tahminimizi yapalım\n",
    "    predicted_value = model.predict(current_window , verbose=0)[0,0]\n",
    "    # Tahminler dizimize bu tahminimizi ekleyelim\n",
    "    forecasts.append(predicted_value)\n",
    "    # Şimdi tahminimizi ve son 23 saatlik verileri birleştirerek yeni bir pencere oluşturalım.\n",
    "    current_window = np.insert(current_window[0], current_window.shape[1], predicted_value, axis=0)\n",
    "    current_window = current_window[1:]\n",
    "    current_window = current_window.reshape((1, current_window.shape[0], current_window.shape[1]))\n",
    "\n",
    "# Tahminleri geri ölçeklendirin ve future_data'yı güncelleyin\n",
    "# X_forecast_3d[:,0] = forecasts\n",
    "# X_forecast_3d = scaler.inverse_transform(X_forecast_3d.reshape(-1, 20)).reshape(-1, 24, 20)\n",
    "# predictions = X_forecast_3d[:, :, 0].reshape(-1)\n",
    "\n",
    "forecasts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_metrics import preds_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_data_vis = data[20900:21500]['Dağıtılan Enerji (MWh)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast['Dağıtılan Enerji (MWh)'] = forecasts\n",
    "future_data_vis = forecast['Dağıtılan Enerji (MWh)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data_vis = data[data.index.month == 8]['Dağıtılan Enerji (MWh)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vis = data['Dağıtılan Enerji (MWh)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Normal all data mean : {data_vis.mean()}\\n')\n",
    "print(f'Anomaly data mean : {anomaly_data_vis.mean()}\\n')\n",
    "print(f'Target data mean : {target_data_vis.mean()}\\n')\n",
    "print(f'Future data mean : {future_data_vis.mean()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,12) , dpi = 100)\n",
    "preds_plot(data_vis , future_data_vis , target_data_vis , anomaly_data_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Done."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
